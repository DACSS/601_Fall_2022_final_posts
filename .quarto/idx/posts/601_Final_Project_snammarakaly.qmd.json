{"title":"Final Project","markdown":{"yaml":{"title":"Final Project","author":"Siddharth Nammara Kalyana Raman","desription":"Final Project on Philadelphia Crime data","date":"12/14/2022","format":{"html":{"toc":true,"code-fold":true,"code-copy":true,"code-tools":true}}},"headingText":"Introduction","containsRefs":false,"markdown":"\n\nAccording to the Police Foundation's the crime analysis is defined as the qualitative and quantitative study of crime and law enforcement information in combination with socio-demographic and spatial factors to apprehend criminals, prevent crime, reduce disorder, and evaluate organizational procedures. \n\nThe primary purpose of crime analysis is to assist or support a police department's operations. These activities include patrolling, patrolling operations, crime prevention and reduction methods, problem-solving, evaluation and accountability of police actions, criminal investigation, arrest, and prosecution. Crime analysis would not be possible without police forces.\n\nSo in this project we have taken a small sample of Philadelphia crime data to perform some statistical analysis and understand their trends. The dataset was taken from OpenDataPhilly. The OpenDataPhilly is a source for the open data in the Philadelphia region. \n\nSome of the questions to which I want to find out the answers are :\n  \nWhat are the different categories of crime happening in Philadelphia and what are the most common crimes?\n\nHow is the trend of crime as the years progress, whether the crimes are increasing or decreasing? This will help us to determine whether the strategies implemented by the police force to reduce the crime rate is working or not.\n\nThe month with the most number of crimes?\n\nThe hour with the most number of crimes?\n\nThe district in Philadelphia with most number of crimes?\n\nThe answers to the above three questions will help us to determine when and where do we need to increase the security?\n\n\n\n```{r}\n#Loading libraries\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(summarytools)\nlibrary(readxl)\nload(\"snkraman_final.RData\")\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n\n\n## Import the Data\n\nImporting the Philadelphia crime data into R.\n```{r}\n#dataset<-read_csv(\"snkraman_final.RData\")\nhead(dataset)\n```\n\n## Dataset Summary\n\nThe columns and their descriptions are as follows :\n\n1. Dc_Dist - A two character field that names the District boundary.\n\n2. Psa - It is a single character field that names the Police Service Area boundary.\n\n3. DC_Key - The unique identifier of the crime that consists of Year+District+Unique ID.\n\n4. Dispatch_Date_Time - The date and time that the officer was dispatched to the scene.\n\n5. Dispatch_Date - It is the dispatch date formatted as character.\n\n6. Dispatch_Time - It is the dispatach time formatted as character.\n\n7. Hour - It is the generalized hour of the dispatched time.\n\n8. Location_Block - The location of crime generalized by the street block.\n\n9. UCR_General - Universal Crime Reporting, it is used to compare crimes in other areas.\n\n10. Text_General_Code - It defines the crime category.\n\n11. Police_Districts - It defines the police district where the crime happened.\n\n12. Month - It defines the month and year on which the crime happened.\n\n13. Lon - Longitude of the crime location.\n\n14. Lat - Latitude of the crime location.\n\n```{r}\nprint(dfSummary(dataset, \n                varnumbers= FALSE, \n                plain.ascii= FALSE, \n                style= \"grid\", \n                graph.magnif= 0.80, \n                valid.col= TRUE),\n      method= 'render', \n      table.classes= 'table-condensed')\n```\n\n##Tidy Data\n```{r}\nhead(dataset)\n```\n```{r}\ntail(dataset)\n```\n\nCheck the number of rows that has null data in the dataset.\n```{r}\nsum(is.na(dataset))\n```\n\nChecking the attributes that has null data.\n```{r}\ncols_null_data<-colSums(is.na(dataset))\ncolnames(dataset)[cols_null_data>0]\n```\n\nChecking the number of rows in each column that has null data.\n```{r}\nsum(is.na(dataset$UCR_General))\nsum(is.na(dataset$Police_Districts))\nsum(is.na(dataset$Lon))\nsum(is.na(dataset$Lat))\n```\n\nRemoving the rows from the dataset that has latitude and longitude as a null value.\n```{r}\ndataset<-subset(dataset,dataset$Lat!=\"NA\" & dataset$Lon!=\"NA\")\nhead(dataset)\n```\nChecking whether there are any rows that has latitude and longitude as the null values after filtering the dataset.\n```{r}\nsum(is.na(dataset$Lon))\nsum(is.na(dataset$Lat))\n```\n## Processing and Visualization\n\nThe Text_General_Code represents the crime category.\n```{r}\nsum(is.na(dataset$Text_General_Code))\n```\n\nWe are calculating the number of occurrences of each crime type in the dataset.\n```{r}\ncountData<- dataset%>%count(Text_General_Code)\ncountData<-countData[-c(1),]\ncountData\n```\nNow we are going to see the visualized representation of each occurrence of crime category in Philadelphia.\n```{r}\nlibrary(ggplot2)\nggplot(data = countData, mapping = aes(x= n, y= reorder(Text_General_Code, n)))+\n  geom_col(aes(fill = Text_General_Code))+\n  geom_text(data = countData[c(1,33),],mapping = aes(label = n))+\n   theme_minimal()+\n  labs(title = \"Crime Category and their Frequency in Philadelphia\",\n       y = NULL,\n       x = \"Frequency\")+\n theme(legend.position = \"none\")\n```\n\nRearranging the data in decreasing order so that it would be helpful for us to know the major crimes happening in the city.\n```{r}\ncountData<-countData[order(countData$n,decreasing = T),]\ncountData\n```\n\nExtracting the data of the top 10 crimes happening in Philadelphia.\n```{r}\ntop_crime_data<-countData[1:10,]\ntop_crime_data\n```\n\n```{r}\nggplot(data = top_crime_data, mapping = aes(x= n, y= reorder(Text_General_Code, n)))+\n  geom_col(aes(fill = Text_General_Code))+\n  geom_text(data = top_crime_data[c(1,10),],mapping = aes(label = n))+\n   theme_minimal()+\n  labs(title = \"Common Crime Category in San Francisco\",\n       y = NULL,\n       x = \"Frequency\")+\n theme(legend.position = \"none\")\n```\n\nFrom the above graph we can see that \"All Other Offenses\" crime category is the most frequently occurring crime. All the other crimes are similar in range to their neighbors but the frequency of \"All Other Offenses\" is quite high compared to the other crime categories.\n\nNow we are going to perform crime analysis per month. In the below code we are extracting the month and year on which the crime has happened from Dispatch_Date and making them as a separate attribute so that we can perform analysis on that.\n```{r}\nhead(dataset)\n```\n```{r}\n#this frame was used to separate Year and Month from the dataset.\n#But as we took the image of the dataset there is no need to run this block as the Dispatch_Date column is overridden in the new frame\n\n#dataset<- dataset %>%\n # separate(`Dispatch_Date`,c('Year','Month'),sep = \"-\")\n\n#head(dataset)\n```\n\nCount the number of crimes happened on each year from 2006 to 2017.\n```{r}\ncountCrimeByYear <- dataset %>% \n  group_by(Year) %>% \n  summarise(total = n())\ncountCrimeByYear\n```\n\n\n```{r}\nggplot(countCrimeByYear, aes(x=Year, y=total)) + \n  geom_point(size=3) + \n  geom_segment(aes(x=Year, \n                   xend=Year, \n                   y=0, \n                   yend=total)) + \n  labs(title=\"Average Crimes per Year in Philadelphia\", \n       caption=\"source: mpg\") + \n  theme(axis.text.x = element_text(angle=65, vjust=0.6))\n```\n\nThe above plot shows the trend of the crime as the year progresses. We can see that on an average the crime has decreased by a great factor as the years progressed. \n\nCount the number of crimes happened on each month for all the years from 2006 to 2017.\n```{r}\ncountCrimeByMonth <- dataset %>% \n  group_by(Month) %>% \n  summarise(total = n())\nhead(countCrimeByMonth)\n```\n```{r}\nhead(countCrimeByMonth)\ntheme_set(theme_classic())\n\nggplot(countCrimeByMonth, aes(x = Month, y = total))+\n  geom_col(fill = \"firebrick3\")+\n  theme_minimal()+\n  labs(\n    title = \"Crime per Month in Philadelphia\",\n    subtitle = \"From 2006 to 2017\",\n    x = \"Month\",\n    y = \"Total Crime\"\n  )\n```\n\nCounting the number of crimes happened at each hour.\n```{r}\ncountCrimeByHour <- dataset %>% \n  group_by(Hour) %>% \n  summarise(total = n())\nhead(countCrimeByHour)\n```\n\n\n```{r}\nlibrary(scales)\ntheme_set(theme_classic())\n\n# Plot\nggplot(countCrimeByHour, aes(x=countCrimeByHour$Hour, y=countCrimeByHour$total)) + \n  geom_point(col=\"tomato2\", size=3) +   # Draw points\n  geom_segment(aes(x=countCrimeByHour$Hour, \n                   xend=countCrimeByHour$Hour, \n                   y=min(countCrimeByHour$total), \n                   yend=max(countCrimeByHour$total)), \n               linetype=\"dashed\", \n               size=0.1) +   # Draw dashed lines\n  labs(title=\"Dot Plot for the number of crimes per hour\", \n       caption=\"source: mpg\") +  \n  coord_flip()\n```\n\n```{r}\ncountCrimeByHour <- dataset %>% \n  group_by(Hour) %>% \n  summarise(total = n())\ncountCrimeByHour<-countCrimeByHour[order(countCrimeByHour$total,decreasing = T),]\ncountCrimeByHour<-head(countCrimeByHour)\ncountCrimeByHour\n```\n\n```{r}\nlibrary(scales)\ntheme_set(theme_classic())\n\n# Plot\nggplot(countCrimeByHour, aes(x=countCrimeByHour$Hour, y=countCrimeByHour$total)) + \n  geom_point(col=\"tomato2\", size=3) +   # Draw points\n  geom_segment(aes(x=countCrimeByHour$Hour, \n                   xend=countCrimeByHour$Hour, \n                   y=min(countCrimeByHour$total), \n                   yend=max(countCrimeByHour$total)), \n               linetype=\"dashed\", \n               size=0.1) +   # Draw dashed lines\n  labs(title=\"Dot Plot for the number of crimes per hour\", \n       caption=\"source: mpg\") +  \n  coord_flip()\n```\n\nThough from the above graph we can see that the max number of crimes happened at 16:00 hours, in order to infer the time range we need gather information from the first graph and see the collective time range in which maximum number of crimes are happening. \n\nNow we will analyse the number of crimes per district. Below we are counting the number of crimes happened in each district.\n```{r}\ncountCrimeByPoliceDistrict<- dataset %>% \n  group_by(Police_Districts) %>% \n  summarise(total = n())\nhead(countCrimeByPoliceDistrict)\n```\nIn order to know the top 6 districts where the most crimes are happening, we'll first rearrange the data in descending order and take the top 6 rows from the dataframe. You can see the top 6 districts and the number of crimes happening in each district clearly below.\n```{r}\ncountTopCrimeByPoliceDistrict<-countCrimeByPoliceDistrict[order(countCrimeByPoliceDistrict$total,decreasing = T),]\ncountTopCrimeByPoliceDistrict<-head(countTopCrimeByPoliceDistrict)\ncountTopCrimeByPoliceDistrict\n```\n\nWe'll plot a pie chart for the above data. The below pie chart shows labels of each district and also a color. The label that has the lightest color is the district where most number of crimes are happening and the label with the darkest color is the district where the least number of crimes are happening. You can also see their value range in the scale shown beside the pie chart.\n```{r}\nlibrary(ggplot2)\n\nggplot(countTopCrimeByPoliceDistrict, aes(x = \"\", y = \"\", fill = countTopCrimeByPoliceDistrict$total)) +\n  geom_col() +\n  geom_label(aes(label = countTopCrimeByPoliceDistrict$Police_Districts),\n             position = position_stack(vjust = 0.5),\n             show.legend = FALSE) +\n  coord_polar(theta = \"y\")\n```\n\nFrom the above pie chart we can clearly see that \"11\" is the district where the most number of crimes are happening in Philadelphia.\n\nIn the given dataset we have latitude and longitude values. So let's try to plot the crime location in the map. \n\n```{r}\nmap_drug <- dataset %>% \n  filter(Year == 2006) %>% \n  select(Location_Block, Lon, Lat)\nmap_drug<-head(map_drug,50)\nmap_drug\n```\n\n\n```{r}\nlibrary(leaflet)\n\n\nico <- makeIcon(iconUrl = \"https://cdn.iconscout.com/icon/free/png-256/drugs-26-129384.png\",iconWidth=47/2, iconHeight=41/2)\nmap2 <- leaflet()\nmap2 <- addTiles(map2)\nmap2 <- addMarkers(map2, data = map_drug, icon = ico, popup = map_drug[,\"Location_Block\"])\nmap2\n```\nThe above map shows the locations of 50 crime scenes happened around Philadelphia in 2006.\n\n```{r}\n\nmap_drug <- dataset %>% \n  filter(Text_General_Code=='Thefts',Year=='2006') %>% \n  select(Location_Block, Lon, Lat)\nmap_drug<-head(map_drug,50)\nmap_drug\n\n```\n\n```{r}\nlibrary(leaflet)\n\n\nico <- makeIcon(iconUrl = \"https://cdn.iconscout.com/icon/free/png-256/drugs-26-129384.png\",iconWidth=47/2, iconHeight=41/2)\nmap2 <- leaflet()\nmap2 <- addTiles(map2)\nmap2 <- addMarkers(map2, data = map_drug, icon = ico, popup = map_drug[,\"Location_Block\"])\nmap2\n```\n\nThe above map shows the locations of 50 theft crimes happened around Philadelphia in the year 2006.\n\n## Reflection\n\nI've learned a lot from working on this project. Before taking this course I did not have any experience in R. We see a lot of analytics used in stock exchange. Initially, I thought of choosing a stock exchange dataset and work on trends. But when I came across crime analysis dataset, it had the latitude and longitude values and I want to experiment with plotting the values on the map. So I went with crime analytics dataset. After selecting the dataset I did not understand what kind of inferences can I draw from the dataset. Then I got a question in my mind why do we actually need to analyse the crime data and who will be using this. The answer to this question helped me to start my process of analysis, frame different research questions and draw inferences from it. \n\nMy thought process was to understand how each column in the dataset are related. When we find a relation between the columns we can deep dive and narrow down our research further. For example, Initially I found the relation between the crime type and their frequency. Later I went down to find what are most frequent crime categories in Philadelhia.\n\nLater, when I was exploring about the different graphs we can plot with R, I found many interesting plots. But I did not understand how to manipulate the data in order to draw few of the graphs. I need to research and explore new techniques that will help me to manipulate data according to the needs. I tried some new ways to extract and create new column apart from the ones thought in class. \n\nThere were many challenges I faced while I was working on this project. I was using the tutorials and techniques learnt in class and also went through different websites in order to know how to manipulate data and draw plots. R is really a powerful tool and there is a lot for me to explore and learn so that I can draw better inferences and plot better visualizations.\n\n## Conclusion\n\nNow we have answers to all our questions. The common crime categories in Philadelphia are \"All Other Offenses\", \"Other Assaults\", \"Thefts\", \"Vandalism\", \"Theft from Vehicle\". Though all the crime category's frequency are in similar range to their neighbors \"All Other Offenses\" frequency is way greater than other crime categories. From the aboce Lollipop chart we can see that the crime rate has decreased significantly over the years from 2006 to 2017. \n\nFrom the monthly crime plot we can infer that though there are differences in the number of crimes happened in each month there isn't any month that is significantly different from other months. So we can't develop any strategy according to the monthly analysis. \n\nFrom hourly analysis we can infer that the crimes have happened at all the times but if you see collectively as a group most of the crimes have happened between 6pm to 12am. From the pie plot we also know the districts where the most number of crimes happened.\n\nFrom all the above inferences the police need to take strategies like increasing the police force or security during night times, crime prone districts and develop technologies to prevent the crimes. Finally, when we see the yearly plot we can understand that the strategies taken by the Police Force are working as the crime rate has decreased significantly over the years.\n\n## Bibliography\n\nDataset from Kaggle- https://www.kaggle.com/datasets/mchirico/philadelphiacrimedata\n\nReferred crime analysis from - https://cops.usdoj.gov/ric/Publications/cops-w0273-pub.pdf\n\nWickham, H., & Grolemund, G. (2016). R for data science: Visualize, model, transform, tidy, and import data. OReilly Media.\n\nWickham, H. (2019). Advanced R. Chapman and Hall/CRC.\n\nWickham, H. (2010). A layered grammar of graphics. Journal of Computational I and Graphical Statistics, 19(1), 3-28."},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":true,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"601_Final_Project_snammarakaly.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.0.37","execution":{"freeze":"auto"},"smooth-scroll":true,"page-layout":"full","mainfont":"Open Sans","linkcolor":"#881c1c","theme":{"light":["flatly","../styles.scss"],"dark":["darkly","../styles.scss"]},"comments":{"giscus":{"repo":"DACSS/601_Fall_2022","category":"Announcements"}},"toc-location":"right","search":true,"title":"Final Project","author":"Siddharth Nammara Kalyana Raman","desription":"Final Project on Philadelphia Crime data","date":"12/14/2022","code-copy":true},"extensions":{"book":{"multiFile":true}}}}}